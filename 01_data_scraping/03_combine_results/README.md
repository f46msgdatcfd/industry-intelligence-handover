# ğŸ”— Combine Search Results (GCS + SerpAPI + News)

This module consolidates all output CSV files from the three submodules:

- `gcs_google_search_batch`
- `serp_google_search_batch/web_search`
- `serp_google_search_batch/news_search`

It produces a **deduplicated, standardized CSV** for downstream processing.

---

## ğŸš€ How to Run

### âœ… Step 1: Copy CSV files from each submodule

From the root of `01_data_scraping`, run:

```bash
cp gcs_google_search_batch/*.csv combine_results/
cp serp_google_search_batch/web_search/*.csv combine_results/
cp serp_google_search_batch/news_search/*.csv combine_results/
```

You should now have a folder like this:

```
combine_results/
â”œâ”€â”€ merge_csv_results.py
â”œâ”€â”€ search_*.csv
â”œâ”€â”€ serp_api_*.csv
â”œâ”€â”€ news_structured_*.csv
```

---

### â–¶ï¸ Step 2: Run the merge script

```bash
python merge_csv_results.py
```

The output will be saved with an auto-generated filename like:

```
combined_results_20250422_115422.csv
```

---

## ğŸ“Š Unified Output Schema

| Column | Description |
|--------|-------------|
| `title` | Title of the page/news |
| `url` | URL of the result |
| `snippet` | Short excerpt if available |
| `source_type` | One of `gcs`, `web`, or `news` |
| `source_file` | Which file this row originated from |

---

## ğŸ’¡ Notes

- This script works only on **flat files in this folder**.
- It does **not scan subfolders**.
- Make sure to copy only files you want to include in the final merged result.